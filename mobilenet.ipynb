{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import cv2\n",
    "from skimage import exposure\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to the folders containing the training and validation data\n",
    "train_path = 'train1'\n",
    "val_path = 'val1'\n",
    "\n",
    "# Set the batch size and image dimensions for the input to the model\n",
    "batch_size = 10\n",
    "img_size = (224, 224)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    # # Read the image\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Apply contrast stretching\n",
    "    p2, p98 = np.percentile(img, (10, 90))\n",
    "    img = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "\n",
    "    # Normalize the image\n",
    "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "\n",
    "    # Convert the image to 3 channels\n",
    "    img = cv2.merge([img, img, img])\n",
    "    # plt.imshow(img)\n",
    "    # plt.title('img')\n",
    "    # plt.show()\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 111 images belonging to 2 classes.\n",
      "Found 36 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the ImageDataGenerator class for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_image,\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Create an instance of the ImageDataGenerator class for validation data\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image,\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Create generators for the training and validation data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pretrained model with all base layers frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MobileNetV2 model\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=img_size+(3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add a new output layer to the model\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "model1 = Model(inputs=base_model.input, outputs=output_layer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pretrained model with last 20 base layers unfrozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MobileNetV2 model\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=img_size+(3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Add a new output layer to the model\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "model2 = Model(inputs=base_model.input, outputs=output_layer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model fully trained with our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MobileNetV3 model\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=img_size+(3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Add a new output layer to the model\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "model3 = Model(inputs=base_model.input, outputs=output_layer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the models with categorical cross-entropy loss and Adam optimizer\n",
    "model1.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model2.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model3.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Create a ModelCheckpoint callback to save the best weights based on the validation loss\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_weights.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0476 - accuracy: 0.4865\n",
      "Epoch 1: saving model to best_weights.h5\n",
      "12/12 [==============================] - 9s 457ms/step - loss: 1.0476 - accuracy: 0.4865 - val_loss: 0.7903 - val_accuracy: 0.6389\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9943 - accuracy: 0.5135\n",
      "Epoch 2: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 373ms/step - loss: 0.9943 - accuracy: 0.5135 - val_loss: 0.8389 - val_accuracy: 0.3611\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9510 - accuracy: 0.4595\n",
      "Epoch 3: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 347ms/step - loss: 0.9510 - accuracy: 0.4595 - val_loss: 0.7494 - val_accuracy: 0.3611\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8121 - accuracy: 0.5676\n",
      "Epoch 4: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 0.8121 - accuracy: 0.5676 - val_loss: 0.6544 - val_accuracy: 0.6389\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8142 - accuracy: 0.5315\n",
      "Epoch 5: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 359ms/step - loss: 0.8142 - accuracy: 0.5315 - val_loss: 0.6572 - val_accuracy: 0.6389\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6963 - accuracy: 0.6126\n",
      "Epoch 6: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 354ms/step - loss: 0.6963 - accuracy: 0.6126 - val_loss: 0.6592 - val_accuracy: 0.6389\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7304 - accuracy: 0.5856\n",
      "Epoch 7: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 402ms/step - loss: 0.7304 - accuracy: 0.5856 - val_loss: 0.6545 - val_accuracy: 0.6389\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7368 - accuracy: 0.5946\n",
      "Epoch 8: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 389ms/step - loss: 0.7368 - accuracy: 0.5946 - val_loss: 0.6586 - val_accuracy: 0.6389\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6793 - accuracy: 0.5766\n",
      "Epoch 9: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 395ms/step - loss: 0.6793 - accuracy: 0.5766 - val_loss: 0.6592 - val_accuracy: 0.6389\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6775 - accuracy: 0.5495\n",
      "Epoch 10: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 358ms/step - loss: 0.6775 - accuracy: 0.5495 - val_loss: 0.6546 - val_accuracy: 0.6389\n",
      "Epoch 11/20\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.7271 - accuracy: 0.6182\n",
      "Epoch 11: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 343ms/step - loss: 0.7268 - accuracy: 0.6126 - val_loss: 0.6617 - val_accuracy: 0.6389\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8050 - accuracy: 0.4775\n",
      "Epoch 12: saving model to best_weights.h5\n",
      "12/12 [==============================] - 6s 478ms/step - loss: 0.8050 - accuracy: 0.4775 - val_loss: 0.7256 - val_accuracy: 0.3611\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7576 - accuracy: 0.5676\n",
      "Epoch 13: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.7576 - accuracy: 0.5676 - val_loss: 0.6725 - val_accuracy: 0.6389\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6989 - accuracy: 0.5766\n",
      "Epoch 14: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.6989 - accuracy: 0.5766 - val_loss: 0.6562 - val_accuracy: 0.6389\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6531 - accuracy: 0.5946\n",
      "Epoch 15: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 348ms/step - loss: 0.6531 - accuracy: 0.5946 - val_loss: 0.6550 - val_accuracy: 0.6389\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7231 - accuracy: 0.5946\n",
      "Epoch 16: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 353ms/step - loss: 0.7231 - accuracy: 0.5946 - val_loss: 0.6592 - val_accuracy: 0.6389\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6714 - accuracy: 0.6126\n",
      "Epoch 17: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.6714 - accuracy: 0.6126 - val_loss: 0.6543 - val_accuracy: 0.6389\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6801 - accuracy: 0.6036\n",
      "Epoch 18: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 340ms/step - loss: 0.6801 - accuracy: 0.6036 - val_loss: 0.6561 - val_accuracy: 0.6389\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7162 - accuracy: 0.5946\n",
      "Epoch 19: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 342ms/step - loss: 0.7162 - accuracy: 0.5946 - val_loss: 0.6543 - val_accuracy: 0.6389\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7031 - accuracy: 0.5856\n",
      "Epoch 20: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 334ms/step - loss: 0.7031 - accuracy: 0.5856 - val_loss: 0.6640 - val_accuracy: 0.6389\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9544 - accuracy: 0.6126\n",
      "Epoch 1: saving model to best_weights.h5\n",
      "12/12 [==============================] - 10s 483ms/step - loss: 0.9544 - accuracy: 0.6126 - val_loss: 1.7910 - val_accuracy: 0.6389\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9383 - accuracy: 0.4595\n",
      "Epoch 2: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 384ms/step - loss: 0.9383 - accuracy: 0.4595 - val_loss: 3.4883 - val_accuracy: 0.6389\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7675 - accuracy: 0.5946\n",
      "Epoch 3: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 385ms/step - loss: 0.7675 - accuracy: 0.5946 - val_loss: 1.4755 - val_accuracy: 0.6389\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7036 - accuracy: 0.5586\n",
      "Epoch 4: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 389ms/step - loss: 0.7036 - accuracy: 0.5586 - val_loss: 2.6417 - val_accuracy: 0.6389\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6764 - accuracy: 0.6036\n",
      "Epoch 5: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 386ms/step - loss: 0.6764 - accuracy: 0.6036 - val_loss: 1.9681 - val_accuracy: 0.6389\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7008 - accuracy: 0.5495\n",
      "Epoch 6: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 385ms/step - loss: 0.7008 - accuracy: 0.5495 - val_loss: 1.0966 - val_accuracy: 0.6389\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6999 - accuracy: 0.5135\n",
      "Epoch 7: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 410ms/step - loss: 0.6999 - accuracy: 0.5135 - val_loss: 1.5409 - val_accuracy: 0.6389\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.6126\n",
      "Epoch 8: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 404ms/step - loss: 0.6564 - accuracy: 0.6126 - val_loss: 2.3415 - val_accuracy: 0.6389\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6737 - accuracy: 0.5856\n",
      "Epoch 9: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 413ms/step - loss: 0.6737 - accuracy: 0.5856 - val_loss: 1.5045 - val_accuracy: 0.6389\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.5676\n",
      "Epoch 10: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 374ms/step - loss: 0.7059 - accuracy: 0.5676 - val_loss: 1.8348 - val_accuracy: 0.6389\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7387 - accuracy: 0.6036\n",
      "Epoch 11: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 409ms/step - loss: 0.7387 - accuracy: 0.6036 - val_loss: 3.3710 - val_accuracy: 0.6389\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6699 - accuracy: 0.6036\n",
      "Epoch 12: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 381ms/step - loss: 0.6699 - accuracy: 0.6036 - val_loss: 1.0936 - val_accuracy: 0.6389\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6622 - accuracy: 0.6216\n",
      "Epoch 13: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 385ms/step - loss: 0.6622 - accuracy: 0.6216 - val_loss: 0.6622 - val_accuracy: 0.6389\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6884 - accuracy: 0.5135\n",
      "Epoch 14: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 374ms/step - loss: 0.6884 - accuracy: 0.5135 - val_loss: 0.7182 - val_accuracy: 0.3611\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7000 - accuracy: 0.5405\n",
      "Epoch 15: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 387ms/step - loss: 0.7000 - accuracy: 0.5405 - val_loss: 0.8856 - val_accuracy: 0.6389\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6653 - accuracy: 0.6216\n",
      "Epoch 16: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 385ms/step - loss: 0.6653 - accuracy: 0.6216 - val_loss: 1.9381 - val_accuracy: 0.6389\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6565 - accuracy: 0.6396\n",
      "Epoch 17: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 389ms/step - loss: 0.6565 - accuracy: 0.6396 - val_loss: 1.7039 - val_accuracy: 0.6389\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6875 - accuracy: 0.5946\n",
      "Epoch 18: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 395ms/step - loss: 0.6875 - accuracy: 0.5946 - val_loss: 1.5852 - val_accuracy: 0.6389\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6869 - accuracy: 0.5676\n",
      "Epoch 19: saving model to best_weights.h5\n",
      "12/12 [==============================] - 5s 385ms/step - loss: 0.6869 - accuracy: 0.5676 - val_loss: 1.2549 - val_accuracy: 0.6389\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6733 - accuracy: 0.5856\n",
      "Epoch 20: saving model to best_weights.h5\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.6733 - accuracy: 0.5856 - val_loss: 2.1287 - val_accuracy: 0.6389\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0146 - accuracy: 0.4955\n",
      "Epoch 1: saving model to best_weights.h5\n",
      "12/12 [==============================] - 30s 1s/step - loss: 1.0146 - accuracy: 0.4955 - val_loss: 1.6564 - val_accuracy: 0.3611\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7073 - accuracy: 0.6036\n",
      "Epoch 2: saving model to best_weights.h5\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.7073 - accuracy: 0.6036 - val_loss: 1.0572 - val_accuracy: 0.6389\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.5946\n",
      "Epoch 3: saving model to best_weights.h5\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.6872 - accuracy: 0.5946 - val_loss: 0.6975 - val_accuracy: 0.6389\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6670 - accuracy: 0.6577\n",
      "Epoch 4: saving model to best_weights.h5\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.6670 - accuracy: 0.6577 - val_loss: 2.2776 - val_accuracy: 0.6389\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6321 - accuracy: 0.6306\n",
      "Epoch 5: saving model to best_weights.h5\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.6321 - accuracy: 0.6306 - val_loss: 1.2818 - val_accuracy: 0.6389\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5492 - accuracy: 0.7207\n",
      "Epoch 6: saving model to best_weights.h5\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.5492 - accuracy: 0.7207 - val_loss: 3.0463 - val_accuracy: 0.6389\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4835 - accuracy: 0.7387\n",
      "Epoch 7: saving model to best_weights.h5\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.4835 - accuracy: 0.7387 - val_loss: 0.6579 - val_accuracy: 0.6389\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4624 - accuracy: 0.8198\n",
      "Epoch 8: saving model to best_weights.h5\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.4624 - accuracy: 0.8198 - val_loss: 0.8523 - val_accuracy: 0.6389\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.7838\n",
      "Epoch 9: saving model to best_weights.h5\n",
      "12/12 [==============================] - 17s 1s/step - loss: 0.4562 - accuracy: 0.7838 - val_loss: 0.7109 - val_accuracy: 0.3611\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4152 - accuracy: 0.8288\n",
      "Epoch 10: saving model to best_weights.h5\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.4152 - accuracy: 0.8288 - val_loss: 3.4246 - val_accuracy: 0.6389\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6296 - accuracy: 0.8018\n",
      "Epoch 11: saving model to best_weights.h5\n",
      "12/12 [==============================] - 18s 1s/step - loss: 0.6296 - accuracy: 0.8018 - val_loss: 4.6996 - val_accuracy: 0.6389\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.7387\n",
      "Epoch 12: saving model to best_weights.h5\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.5616 - accuracy: 0.7387 - val_loss: 4.9433 - val_accuracy: 0.6389\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5037 - accuracy: 0.8108\n",
      "Epoch 13: saving model to best_weights.h5\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.5037 - accuracy: 0.8108 - val_loss: 0.7550 - val_accuracy: 0.6389\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8288\n",
      "Epoch 14: saving model to best_weights.h5\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.3819 - accuracy: 0.8288 - val_loss: 4.8999 - val_accuracy: 0.6389\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5994 - accuracy: 0.7297\n",
      "Epoch 15: saving model to best_weights.h5\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.5994 - accuracy: 0.7297 - val_loss: 3.5035 - val_accuracy: 0.6389\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5073 - accuracy: 0.7838\n",
      "Epoch 16: saving model to best_weights.h5\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.5073 - accuracy: 0.7838 - val_loss: 3.1150 - val_accuracy: 0.6389\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4947 - accuracy: 0.7568\n",
      "Epoch 17: saving model to best_weights.h5\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.4947 - accuracy: 0.7568 - val_loss: 1.4470 - val_accuracy: 0.6389\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.8649\n",
      "Epoch 18: saving model to best_weights.h5\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.3221 - accuracy: 0.8649 - val_loss: 5.1778 - val_accuracy: 0.6389\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5086 - accuracy: 0.8288\n",
      "Epoch 19: saving model to best_weights.h5\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.5086 - accuracy: 0.8288 - val_loss: 1.0193 - val_accuracy: 0.3611\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5046 - accuracy: 0.7748\n",
      "Epoch 20: saving model to best_weights.h5\n",
      "12/12 [==============================] - 16s 1s/step - loss: 0.5046 - accuracy: 0.7748 - val_loss: 1.4933 - val_accuracy: 0.3611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d000d1a50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the generators\n",
    "model1.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "model2.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "model3.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.evaluate(val_generator)\n",
    "# model2.evaluate(val_generator)\n",
    "# model3.evaluate(val_generator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 images belonging to 2 classes.\n",
      "4/4 [==============================] - 1s 196ms/step\n",
      "4/4 [==============================] - 1s 197ms/step\n",
      "4/4 [==============================] - 1s 216ms/step\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "model1: All base layers frozen.\n",
      "[[23  0]\n",
      " [13  0]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Reccurant       0.64      1.00      0.78        23\n",
      "Non-reccurant       0.00      0.00      0.00        13\n",
      "\n",
      "     accuracy                           0.64        36\n",
      "    macro avg       0.32      0.50      0.39        36\n",
      " weighted avg       0.41      0.64      0.50        36\n",
      "\n",
      "model2: All base layers frozen but last 20 unfrozen.\n",
      "[[23  0]\n",
      " [13  0]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Reccurant       0.64      1.00      0.78        23\n",
      "Non-reccurant       0.00      0.00      0.00        13\n",
      "\n",
      "     accuracy                           0.64        36\n",
      "    macro avg       0.32      0.50      0.39        36\n",
      " weighted avg       0.41      0.64      0.50        36\n",
      "\n",
      "model3: Training all layers with our dataset.\n",
      "[[ 0 23]\n",
      " [ 0 13]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Reccurant       0.00      0.00      0.00        23\n",
      "Non-reccurant       0.36      1.00      0.53        13\n",
      "\n",
      "     accuracy                           0.36        36\n",
      "    macro avg       0.18      0.50      0.27        36\n",
      " weighted avg       0.13      0.36      0.19        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the test data generator and load the test set\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image,\n",
    "    rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    \"val1\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get the true labels of the test set\n",
    "true_labels = test_set.classes\n",
    "\n",
    "# Make predictions on the test set\n",
    "pred_probs_1 = model1.predict(test_set, verbose=1)\n",
    "pred_probs_2 = model2.predict(test_set, verbose=1)\n",
    "pred_probs_3 = model3.predict(test_set, verbose=1)\n",
    "# print(pred_probs_1)\n",
    "pred_labels_1 = np.argmax(pred_probs_1, axis=1)\n",
    "pred_labels_2 = np.argmax(pred_probs_2, axis=1)\n",
    "pred_labels_3 = np.argmax(pred_probs_3, axis=1)\n",
    "print(true_labels)\n",
    "print(pred_labels_1)\n",
    "print(pred_labels_2)\n",
    "print(pred_labels_3)\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm1 = confusion_matrix(true_labels, pred_labels_1)\n",
    "cm2 = confusion_matrix(true_labels, pred_labels_2)\n",
    "cm3 = confusion_matrix(true_labels, pred_labels_3)\n",
    "print(\"model1: All base layers frozen.\")\n",
    "print(cm1)\n",
    "print(classification_report(true_labels, pred_labels_1, target_names=['Reccurant', 'Non-reccurant']))\n",
    "print(\"model2: All base layers frozen but last 20 unfrozen.\")\n",
    "print(cm2)\n",
    "print(classification_report(true_labels, pred_labels_2, target_names=['Reccurant', 'Non-reccurant']))\n",
    "print(\"model3: Training all layers with our dataset.\")\n",
    "print(cm3)\n",
    "print(classification_report(true_labels, pred_labels_3, target_names=['Reccurant', 'Non-reccurant']))\n",
    "\n",
    "# # Calculate the accuracy, precision, recall, and f1 score\n",
    "# accuracy = accuracy_score(true_labels, pred_labels)\n",
    "# precision = precision_score(true_labels, pred_labels)\n",
    "# recall = recall_score(true_labels, pred_labels)\n",
    "# f1 = f1_score(true_labels, pred_labels)\n",
    "\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Confusion Matrix:\\n\", cm)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"Precision:\", precision)\n",
    "# print(\"Recall:\", recall)\n",
    "# print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# for layer in model.layers[len(model.layers)-7:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "# model.compile(\n",
    "#     loss='categorical_crossentropy',\n",
    "#     optimizer=optimizer,\n",
    "#     metrics=['accuracy', 'Precision', 'Recall']\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
